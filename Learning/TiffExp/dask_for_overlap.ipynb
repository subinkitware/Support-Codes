{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of merged elements  0\n"
     ]
    }
   ],
   "source": [
    "# without dask\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np\n",
    "import json\n",
    "import dask.array as da\n",
    "import dask\n",
    "\n",
    "# dask arrays are the one which delays the processing here.\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    all_data = json.load(json_file)\n",
    "data = all_data\n",
    "len(data)\n",
    "\n",
    "\n",
    "# load all points to one stacknp.max([sublist[1] for sublist in sample['points']])\n",
    "pop_list = []\n",
    "merged_polygons = []\n",
    "sample_element = data[0]\n",
    "for i, sample in enumerate(data):\n",
    "    curr_x = np.max([sublist[1] for sublist in sample['points']])\n",
    "    curr_y = np.max([sublist[1] for sublist in sample['points']])\n",
    "    for j in range(i+1, len(data)-1):\n",
    "        given_x = np.max([sublist[0] for sublist in data[j]['points']])\n",
    "        given_y = np.max([sublist[1] for sublist in data[j]['points']])\n",
    "        if given_x < curr_x+500 and given_y < curr_y + 500:\n",
    "            if Polygon(sample['points']).intersects(Polygon(data[j]['points'])):\n",
    "                merged_polygon = unary_union(\n",
    "                    [Polygon(sample['points']),\n",
    "                     Polygon(data[j]['points'])])\n",
    "                merged_polygons.append(merged_polygon)\n",
    "                if i not in pop_list:\n",
    "                    pop_list.append(i)\n",
    "                if j not in pop_list:\n",
    "                    pop_list.append(j)\n",
    "\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "    # Sort the indexes in descending order\n",
    "    indexes.sort(reverse=True)\n",
    "\n",
    "    # Remove the elements at the specified indexes\n",
    "    for index in indexes:\n",
    "        if 0 <= index < len(lst):\n",
    "            del lst[index]\n",
    "\n",
    "    return lst\n",
    "\n",
    "\n",
    "new_list = remove_indexes(data, pop_list)\n",
    "\n",
    "# convert all the data in merged_polygons to json\n",
    "if merged_polygons:\n",
    "    for elements in merged_polygons:\n",
    "        rlist = list(elements.exterior.coords)\n",
    "        sample_element['points'] = rlist\n",
    "        data.append(sample_element)\n",
    "\n",
    "print('number of merged elements ', len(merged_polygons))\n",
    "\n",
    "#time 4.8s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multiprocessing without any class structure (14 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of merged elements  0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import unary_union\n",
    "import numpy as np\n",
    "import json\n",
    "import multiprocess\n",
    "from functools import partial  # Import the 'partial' function from functools\n",
    "\n",
    "\n",
    "def find_overlapping_polygons(sample_idx, data):\n",
    "    merged_polygons = []\n",
    "    sample = data[sample_idx]\n",
    "    curr_x = np.max([sublist[0] for sublist in sample['points']])\n",
    "    curr_y = np.max([sublist[1] for sublist in sample['points']])\n",
    "    for j in range(sample_idx + 1, len(data)-1):\n",
    "        given_x = np.max([sublist[0] for sublist in data[j]['points']])\n",
    "        given_y = np.max([sublist[1] for sublist in data[j]['points']])\n",
    "        if given_x < curr_x + 500 and given_y < curr_y + 500:\n",
    "            if Polygon(sample['points']).intersects(Polygon(data[j]['points'])):\n",
    "                merged_polygon = unary_union(\n",
    "                    [Polygon(sample['points']),\n",
    "                     Polygon(data[j]['points'])])\n",
    "                merged_polygons.append(merged_polygon)\n",
    "    return merged_polygons\n",
    "\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    # Create a pool of workers\n",
    "pool = multiprocess.Pool(processes=multiprocess.cpu_count())\n",
    "\n",
    "# Create a partial function for find_overlapping_polygons with fixed 'data' argument\n",
    "find_overlapping_partial = partial(find_overlapping_polygons, data=data)\n",
    "\n",
    "# Use multiprocessing to parallelize the loop for finding overlapping polygons\n",
    "merged_polygons = pool.map(find_overlapping_partial, range(len(data)))\n",
    "\n",
    "# Close the pool of workers\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# Flatten the list of merged polygons\n",
    "merged_polygons = [poly for sublist in merged_polygons for poly in sublist]\n",
    "\n",
    "print('number of merged elements ', len(merged_polygons))\n",
    "\n",
    "#time 14s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using bbox method with concurrent futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function find_bbox at 0x7f09515796c0>: it's not the same object as __main__.find_bbox",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/local/KHQ/s.erattakulangara/anaconda3/envs/tiffexp/lib/python3.10/multiprocessing/queues.py\", line 245, in _feed\n    obj = _ForkingPickler.dumps(obj)\n  File \"/home/local/KHQ/s.erattakulangara/anaconda3/envs/tiffexp/lib/python3.10/multiprocessing/reduction.py\", line 51, in dumps\n    cls(buf, protocol).dump(obj)\n_pickle.PicklingError: Can't pickle <function find_bbox at 0x7f09515796c0>: it's not the same object as __main__.find_bbox\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 49\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[39mreturn\u001b[39;00m j\n\u001b[1;32m     48\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor() \u001b[39mas\u001b[39;00m executer:\n\u001b[0;32m---> 49\u001b[0m     bbbox_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(executer\u001b[39m.\u001b[39;49mmap(pfind_bbox, (i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(data)))))\n\u001b[1;32m     50\u001b[0m     overlapping_bbox \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m     51\u001b[0m         \u001b[39mset\u001b[39m(executer\u001b[39m.\u001b[39mmap(find_overlapping_nuclei_indexes, (i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(bbbox_list))))))\n\u001b[1;32m     52\u001b[0m     nuclei_remove_indexes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m     53\u001b[0m         \u001b[39mset\u001b[39m(executer\u001b[39m.\u001b[39mmap(remove_overlapping_nuclei, (i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m overlapping_bbox \u001b[39mif\u001b[39;00m i \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m))))\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py:567\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    562\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    568\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    569\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    610\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/multiprocessing/queues.py:245\u001b[0m, in \u001b[0;36mQueue._feed\u001b[0;34m(buffer, notempty, send_bytes, writelock, close, ignore_epipe, onerror, queue_sem)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# serialize the data before acquiring the lock\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m obj \u001b[39m=\u001b[39m _ForkingPickler\u001b[39m.\u001b[39;49mdumps(obj)\n\u001b[1;32m    246\u001b[0m \u001b[39mif\u001b[39;00m wacquire \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     send_bytes(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdumps\u001b[39m(\u001b[39mcls\u001b[39m, obj, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mcls\u001b[39;49m(buf, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[1;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m buf\u001b[39m.\u001b[39mgetbuffer()\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function find_bbox at 0x7f09515796c0>: it's not the same object as __main__.find_bbox"
     ]
    }
   ],
   "source": [
    "# with multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import json\n",
    "from functools import partial\n",
    "\n",
    "# dask arrays are the one which delays the processing here.\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    all_data = json.load(json_file)\n",
    "data = all_data\n",
    "print(len(data))\n",
    "\n",
    "\n",
    "def find_bbox(data, index):\n",
    "    curr_x_max = np.max([sublist[0] for sublist in data[index]['points']])\n",
    "    curr_y_max = np.max([sublist[1] for sublist in data[index]['points']])\n",
    "    curr_x_min = np.min([sublist[0] for sublist in data[index]['points']])\n",
    "    curr_y_min = np.min([sublist[1] for sublist in data[index]['points']])\n",
    "    return curr_x_min, curr_x_max, curr_y_min, curr_y_max\n",
    "\n",
    "\n",
    "def find_overlapping_nuclei_indexes(index):\n",
    "    curr_x_min = bbbox_list[index][0]\n",
    "    curr_x_max = bbbox_list[index][1]\n",
    "    curr_y_min = bbbox_list[index][2]\n",
    "    curr_y_max = bbbox_list[index][3]\n",
    "    for j in range(len(bbbox_list)):\n",
    "        if j == index:\n",
    "            continue\n",
    "        given_x_min = bbbox_list[j][0]\n",
    "        given_x_max = bbbox_list[j][1]\n",
    "        given_y_min = bbbox_list[j][2]\n",
    "        given_y_max = bbbox_list[j][3]\n",
    "        if curr_x_min <= given_x_max and curr_x_max >= given_x_min and curr_y_min <= given_y_max and curr_y_max >= given_y_min:\n",
    "            return j\n",
    "\n",
    "\n",
    "def remove_overlapping_nuclei(index):\n",
    "    for j in range(len(overlapping_bbox)):\n",
    "        if j == index or j == None:\n",
    "            continue\n",
    "        if Polygon(data[index]['points']).intersects(Polygon(data[j]['points'])):\n",
    "            return j\n",
    "\n",
    "\n",
    "with ProcessPoolExecutor() as executer:\n",
    "    bbbox_list = list(executer.map(pfind_bbox, (i for i in range(len(data)))))\n",
    "    overlapping_bbox = list(\n",
    "        set(executer.map(find_overlapping_nuclei_indexes, (i for i in range(len(bbbox_list))))))\n",
    "    nuclei_remove_indexes = list(\n",
    "        set(executer.map(remove_overlapping_nuclei, (i for i in overlapping_bbox if i is not None))))\n",
    "    nuclei_remove_indexes_noNone = [i for i in nuclei_remove_indexes if i is not None]\n",
    "\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "    # Sort the indexes in descending order\n",
    "    indexes.sort(reverse=True)\n",
    "\n",
    "    # Remove the elements at the specified indexes\n",
    "    for index in indexes:\n",
    "        if 0 <= index < len(lst):\n",
    "            del lst[index]\n",
    "\n",
    "    return lst\n",
    "\n",
    "\n",
    "new_list = remove_indexes(data, nuclei_remove_indexes_noNone)\n",
    "\n",
    "\n",
    "print('number of merged elements ', len(nuclei_remove_indexes_noNone))\n",
    "print('total number of nuclei ', len(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concurrent futures without any class structure (0.4 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> starting overlap nuclei removal \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bbbox_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/local/KHQ/s.erattakulangara/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py\", line 243, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/home/local/KHQ/s.erattakulangara/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py\", line 202, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/home/local/KHQ/s.erattakulangara/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py\", line 202, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"/tmp/ipykernel_264570/2625633875.py\", line 18, in find_overlapping_nuclei_indexes\n    curr_x_min = bbbox_list[index][0]\nNameError: name 'bbbox_list' is not defined\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 70\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m>> Number of nuclei after overlap removal \u001b[39m\u001b[39m'\u001b[39m, \u001b[39mlen\u001b[39m(new_list))\n\u001b[1;32m     68\u001b[0m     \u001b[39mreturn\u001b[39;00m new_list\n\u001b[0;32m---> 70\u001b[0m nuclei_list \u001b[39m=\u001b[39m remove_overlap_nuclei(nuclei_list)\n",
      "Cell \u001b[0;32mIn[19], line 60\u001b[0m, in \u001b[0;36mremove_overlap_nuclei\u001b[0;34m(nuclei_list)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mwith\u001b[39;00m ProcessPoolExecutor() \u001b[39mas\u001b[39;00m executer:\n\u001b[1;32m     58\u001b[0m     bbbox_list \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(executer\u001b[39m.\u001b[39mmap(find_bbox, (i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(nuclei_list)))))\n\u001b[1;32m     59\u001b[0m     overlapping_bbox \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[0;32m---> 60\u001b[0m         \u001b[39mset\u001b[39;49m(executer\u001b[39m.\u001b[39;49mmap(find_overlapping_nuclei_indexes, (i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(bbbox_list))))))\n\u001b[1;32m     61\u001b[0m     nuclei_remove_indexes \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m     62\u001b[0m         \u001b[39mset\u001b[39m(executer\u001b[39m.\u001b[39mmap(remove_overlapping_nuclei, (i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m overlapping_bbox \u001b[39mif\u001b[39;00m i \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m))))\n\u001b[1;32m     63\u001b[0m     nuclei_remove_indexes_noNone \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m nuclei_remove_indexes \u001b[39mif\u001b[39;00m i \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py:567\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    562\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m \u001b[39m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    564\u001b[0m \u001b[39m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[39m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m    568\u001b[0m         element\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    569\u001b[0m         \u001b[39mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:609\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[39mwhile\u001b[39;00m fs:\n\u001b[1;32m    607\u001b[0m     \u001b[39m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    608\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39;49mpop()\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    610\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    611\u001b[0m         \u001b[39myield\u001b[39;00m fs\u001b[39m.\u001b[39mpop()\u001b[39m.\u001b[39mresult(end_time \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:446\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    445\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 446\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py:243\u001b[0m, in \u001b[0;36m_process_worker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     r \u001b[39m=\u001b[39m call_item\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39mcall_item\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcall_item\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m    244\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    245\u001b[0m     exc \u001b[39m=\u001b[39m _ExceptionWithTraceback(e, e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py:202\u001b[0m, in \u001b[0;36m_process_chunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_chunk\u001b[39m(fn, chunk):\n\u001b[1;32m    194\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Processes a chunk of an iterable passed to map.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39m    Runs the function passed to map() on a chunk of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mreturn\u001b[39;00m [fn(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m chunk]\n",
      "File \u001b[0;32m~/anaconda3/envs/tiffexp/lib/python3.10/concurrent/futures/process.py:202\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_chunk\u001b[39m(fn, chunk):\n\u001b[1;32m    194\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Processes a chunk of an iterable passed to map.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m \u001b[39m    Runs the function passed to map() on a chunk of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mreturn\u001b[39;00m [fn(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m chunk]\n",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m, in \u001b[0;36mfind_overlapping_nuclei_indexes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_overlapping_nuclei_indexes\u001b[39m(index):\n\u001b[0;32m---> 18\u001b[0m     curr_x_min \u001b[39m=\u001b[39m bbbox_list[index][\u001b[39m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m     curr_x_max \u001b[39m=\u001b[39m bbbox_list[index][\u001b[39m1\u001b[39m]\n\u001b[1;32m     20\u001b[0m     curr_y_min \u001b[39m=\u001b[39m bbbox_list[index][\u001b[39m2\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bbbox_list' is not defined"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    all_data = json.load(json_file)\n",
    "\n",
    "\n",
    "def find_bbox(index):\n",
    "    curr_x_max = np.max([sublist[0] for sublist in nuclei_list[index]['points']])\n",
    "    curr_y_max = np.max([sublist[1] for sublist in nuclei_list[index]['points']])\n",
    "    curr_x_min = np.min([sublist[0] for sublist in nuclei_list[index]['points']])\n",
    "    curr_y_min = np.min([sublist[1] for sublist in nuclei_list[index]['points']])\n",
    "    return curr_x_min, curr_x_max, curr_y_min, curr_y_max\n",
    "\n",
    "\n",
    "def find_overlapping_nuclei_indexes(index):\n",
    "    curr_x_min = bbbox_list[index][0]\n",
    "    curr_x_max = bbbox_list[index][1]\n",
    "    curr_y_min = bbbox_list[index][2]\n",
    "    curr_y_max = bbbox_list[index][3]\n",
    "    for j in range(len(bbbox_list)):\n",
    "        if j == index:\n",
    "            continue\n",
    "        given_x_min = bbbox_list[j][0]\n",
    "        given_x_max = bbbox_list[j][1]\n",
    "        given_y_min = bbbox_list[j][2]\n",
    "        given_y_max = bbbox_list[j][3]\n",
    "        if curr_x_min <= given_x_max and curr_x_max >= given_x_min and curr_y_min <= given_y_max and curr_y_max >= given_y_min:\n",
    "            return j\n",
    "\n",
    "\n",
    "def remove_overlapping_nuclei(index):\n",
    "    for j in range(len(overlapping_bbox)):\n",
    "        if j == index or j == None:\n",
    "            continue\n",
    "        if Polygon(nuclei_list[index]['points']).intersects(Polygon(nuclei_list[j]['points'])):\n",
    "            return j\n",
    "\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "    # Sort the indexes in descending order\n",
    "    indexes.sort(reverse=True)\n",
    "\n",
    "    # Remove the elements at the specified indexes\n",
    "    for index in indexes:\n",
    "        if 0 <= index < len(lst):\n",
    "            del lst[index]\n",
    "\n",
    "    return lst\n",
    "\n",
    "\n",
    "def remove_overlap_nuclei(nuclei_list):\n",
    "\n",
    "    print('>> starting overlap nuclei removal ')\n",
    "\n",
    "    with ProcessPoolExecutor() as executer:\n",
    "        bbbox_list = list(executer.map(find_bbox, (i for i in range(len(nuclei_list)))))\n",
    "        overlapping_bbox = list(\n",
    "            set(executer.map(find_overlapping_nuclei_indexes, (i for i in range(len(bbbox_list))))))\n",
    "        nuclei_remove_indexes = list(\n",
    "            set(executer.map(remove_overlapping_nuclei, (i for i in overlapping_bbox if i is not None))))\n",
    "        nuclei_remove_indexes_noNone = [i for i in nuclei_remove_indexes if i is not None]\n",
    "\n",
    "    new_list = remove_indexes(nuclei_list, nuclei_remove_indexes_noNone)\n",
    "    print('>> Number of nuclei after overlap removal ', len(new_list))\n",
    "\n",
    "    return new_list\n",
    "\n",
    "nuclei_list = remove_overlap_nuclei(nuclei_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pathos for multiprocessing with Bbox method (5 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> starting overlap nuclei removal \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Number of nuclei after overlap removal  780\n"
     ]
    }
   ],
   "source": [
    "# using pathos\n",
    "\n",
    "from pathos.multiprocessing import ProcessingPool\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def remove_overlap_nuclei(nuclei_list):\n",
    "\n",
    "    print('>> starting overlap nuclei removal ')\n",
    "\n",
    "    def _find_bbox(index):\n",
    "        curr_x_max = np.max([sublist[0] for sublist in nuclei_list[index]['points']])\n",
    "        curr_y_max = np.max([sublist[1] for sublist in nuclei_list[index]['points']])\n",
    "        curr_x_min = np.min([sublist[0] for sublist in nuclei_list[index]['points']])\n",
    "        curr_y_min = np.min([sublist[1] for sublist in nuclei_list[index]['points']])\n",
    "        return curr_x_min, curr_x_max, curr_y_min, curr_y_max\n",
    "\n",
    "    def _remove_overlapping_nuclei(index):\n",
    "        for j in range(len(overlapping_bbox)):\n",
    "            if j == index or j == None:\n",
    "                continue\n",
    "            if Polygon(nuclei_list[index]['points']).intersects(Polygon(nuclei_list[j]['points'])):\n",
    "                return j\n",
    "\n",
    "    def _remove_indexes(lst, indexes):\n",
    "        # Sort the indexes in descending order\n",
    "        indexes.sort(reverse=True)\n",
    "\n",
    "        # Remove the elements at the specified indexes\n",
    "        for index in indexes:\n",
    "            if 0 <= index < len(lst):\n",
    "                del lst[index]\n",
    "\n",
    "        return lst\n",
    "\n",
    "    def _find_overlapping_nuclei_indexes(index):\n",
    "        curr_x_min = bbbox_list[index][0]\n",
    "        curr_x_max = bbbox_list[index][1]\n",
    "        curr_y_min = bbbox_list[index][2]\n",
    "        curr_y_max = bbbox_list[index][3]\n",
    "        for j in range(len(bbbox_list)):\n",
    "            if j == index:\n",
    "                continue\n",
    "            given_x_min = bbbox_list[j][0]\n",
    "            given_x_max = bbbox_list[j][1]\n",
    "            given_y_min = bbbox_list[j][2]\n",
    "            given_y_max = bbbox_list[j][3]\n",
    "            if curr_x_min <= given_x_max and curr_x_max >= given_x_min and curr_y_min <= given_y_max and curr_y_max >= given_y_min:\n",
    "                return j\n",
    "\n",
    "    pool = ProcessingPool(2)\n",
    "    bbbox_list = list(pool.map(_find_bbox, (i for i in range(len(nuclei_list)))))\n",
    "    overlapping_bbox = list(\n",
    "        set(pool.map(_find_overlapping_nuclei_indexes, (i for i in range(len(bbbox_list))))))\n",
    "    nuclei_remove_indexes = list(\n",
    "        set(pool.map(_remove_overlapping_nuclei, (i for i in overlapping_bbox if i is not None))))\n",
    "    nuclei_remove_indexes_noNone = [i for i in nuclei_remove_indexes if i is not None]\n",
    "\n",
    "    new_list = _remove_indexes(nuclei_list, nuclei_remove_indexes_noNone)\n",
    "    print('>> Number of nuclei after overlap removal ', len(new_list))\n",
    "\n",
    "    return new_list\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    nuclei_list = json.load(json_file)\n",
    "nuclei_list = remove_overlap_nuclei(nuclei_list)\n",
    "\n",
    "#time 4.8 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using concurrent.futures without class structure with strTree (0.4 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from shapely.geometry import Polygon\n",
    "import shapely\n",
    "import numpy as np\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    nuclei_list = json.load(json_file)\n",
    "\n",
    "def create_polygons(index):\n",
    "    return Polygon(nuclei_list[index]['points'])\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "        # Sort the indexes in descending order\n",
    "        indexes.sort(reverse=True)\n",
    "\n",
    "        # Remove the elements at the specified indexes\n",
    "        for index in indexes:\n",
    "            if 0 <= index < len(lst):\n",
    "                del lst[index]\n",
    "\n",
    "        return lst\n",
    "\n",
    "with ProcessPoolExecutor() as executor:\n",
    "    polys = list((executor.map(create_polygons, (i for i in range(len(nuclei_list))))))\n",
    "rt = shapely.strtree.STRtree(polys)\n",
    "remove_list = [index for index in range(len(polys)) if any(ix for ix in rt.query(polys[index]) if ix < index and polys[index].intersects(polys[ix]))]\n",
    "output_list = remove_indexes(nuclei_list,remove_list)\n",
    "print(len(nuclei_list))\n",
    "print(remove_list)\n",
    "\n",
    "#time 0.3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using conucrrent futures with strTree, Class structure (17 s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780 780\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from shapely.geometry import Polygon\n",
    "import shapely.strtree\n",
    "\n",
    "class NucleiProcessor:\n",
    "\n",
    "    def __init__(self, nuclei_list):\n",
    "        self.nuclei_list = nuclei_list\n",
    "\n",
    "    def create_polygons(self, index):\n",
    "        return Polygon(self.nuclei_list[index]['points'])\n",
    "\n",
    "    def remove_indexes(self, lst, indexes):\n",
    "        # Sort the indexes in descending order\n",
    "        indexes.sort(reverse=True)\n",
    "\n",
    "        # Remove the elements at the specified indexes\n",
    "        for index in indexes:\n",
    "            if 0 <= index < len(lst):\n",
    "                del lst[index]\n",
    "\n",
    "        return lst\n",
    "\n",
    "    def process_nuclei(self):\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            polys = list(executor.map(self.create_polygons, (i for i in range(len(self.nuclei_list)))))\n",
    "\n",
    "        rt = shapely.strtree.STRtree(polys)\n",
    "        remove_list = [index for index in range(len(polys)) if any(ix for ix in rt.query(polys[index]) if ix < index and polys[index].intersects(polys[ix]))]\n",
    "\n",
    "        output_list = self.remove_indexes(self.nuclei_list, remove_list)\n",
    "\n",
    "        return output_list\n",
    "\n",
    "\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    nuclei_list = json.load(json_file)\n",
    "processor = NucleiProcessor(nuclei_list)\n",
    "output_list = processor.process_nuclei()\n",
    "print(len(output_list),len(nuclei_list))\n",
    "\n",
    "#time 17s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using pathos multiprocessing with strTree (0.2 second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from pathos.multiprocessing import ProcessingPool\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "with open('overlapping_large_image.json', 'r') as json_file:\n",
    "    nuclei_list = json.load(json_file)\n",
    "\n",
    "def create_polygons(index):\n",
    "    return Polygon(nuclei_list[index]['points'])\n",
    "\n",
    "def remove_indexes(lst, indexes):\n",
    "        # Sort the indexes in descending order\n",
    "        indexes.sort(reverse=True)\n",
    "\n",
    "        # Remove the elements at the specified indexes\n",
    "        for index in indexes:\n",
    "            if 0 <= index < len(lst):\n",
    "                del lst[index]\n",
    "\n",
    "        return lst\n",
    "\n",
    "pool = ProcessingPool()\n",
    "polys = list((pool.map(create_polygons, (i for i in range(len(nuclei_list))))))\n",
    "print(len(polys))\n",
    "rt = shapely.strtree.STRtree(polys)\n",
    "remove_list = [index for index in range(len(polys)) if any(ix for ix in rt.query(polys[index]) if ix < index and polys[index].intersects(polys[ix]))]\n",
    "output_list = remove_indexes(nuclei_list,remove_list)\n",
    "print(remove_list)\n",
    "#time 0.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiffexp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
